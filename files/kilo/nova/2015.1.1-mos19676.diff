diff --git a/nova/virt/libvirt/driver.py b/nova/virt/libvirt/driver.py
index 1b5c4b9..796c80f 100644
--- a/nova/virt/libvirt/driver.py
+++ b/nova/virt/libvirt/driver.py
@@ -99,6 +99,7 @@ from nova.virt.libvirt import imagecache
 from nova.virt.libvirt import instancejobtracker
 from nova.virt.libvirt import lvm
 from nova.virt.libvirt import rbd_utils
+from nova.virt.libvirt import sio_utils
 from nova.virt.libvirt import utils as libvirt_utils
 from nova.virt.libvirt import vif as libvirt_vif
 from nova.virt import netutils
@@ -285,6 +286,7 @@ libvirt_volume_drivers = [
     'scality=nova.virt.libvirt.volume.LibvirtScalityVolumeDriver',
     'gpfs=nova.virt.libvirt.volume.LibvirtGPFSVolumeDriver',
     'quobyte=nova.virt.libvirt.volume.LibvirtQuobyteVolumeDriver',
+    'scaleio=nova.virt.libvirt.drivers.emc.scaleiolibvirtdriver.LibvirtScaleIOVolumeDriver',
 ]
 
 
@@ -863,6 +865,8 @@ class LibvirtDriver(driver.ComputeDriver):
                 self._cleanup_lvm(instance)
             if CONF.libvirt.images_type == 'rbd':
                 self._cleanup_rbd(instance)
+        if CONF.libvirt.images_type == 'sio':
+            self._cleanup_sio(instance, destroy_disks)
 
         if destroy_disks or (
                 migrate_data and migrate_data.get('is_shared_block_storage',
@@ -924,6 +928,15 @@ class LibvirtDriver(driver.ComputeDriver):
                 ceph_conf=CONF.libvirt.images_rbd_ceph_conf,
                 rbd_user=CONF.libvirt.rbd_user)
 
+    @staticmethod
+    def _get_sio_driver():
+        # TODO(emc): Currently we assume a static ScaleIO protection domain and
+        # storage pool. In the future we will need to have the API library
+        # determine what protection domain and storage pool to use based on
+        # the compute host node information. For now if defined use values
+        # present in conf file
+        return sio_utils.SIODriver()
+
     def _cleanup_rbd(self, instance):
         LibvirtDriver._get_rbd_driver().cleanup_volumes(instance)
 
@@ -957,6 +970,10 @@ class LibvirtDriver(driver.ComputeDriver):
             return disks
         return []
 
+    def _cleanup_sio(self, instance, destroy_disks):
+        LibvirtDriver._get_sio_driver().cleanup_volumes(
+            instance, unmap_only=not destroy_disks)
+
     def get_volume_connector(self, instance):
         if self._initiator is None:
             self._initiator = libvirt_utils.get_iscsi_initiator()
@@ -1009,10 +1026,22 @@ class LibvirtDriver(driver.ComputeDriver):
             utils.execute('rm', '-rf', target, delay_on_retry=True,
                           attempts=5)
 
+        backend = self.image_backend.image(instance, 'disk')
+        # TODO(nic): Set ignore_errors=False in a future release.
+        # It is set to True here to avoid any upgrade issues surrounding
+        # instances being in pending resize state when the software is updated;
+        # in that case there will be no snapshot to remove.  Once it can be
+        # reasonably assumed that no such instances exist in the wild
+        # anymore, it should be set back to False (the default) so it will
+        # throw errors, like it should.
+        backend.remove_snap(libvirt_utils.RESIZE_SNAPSHOT_NAME,
+                            ignore_errors=True)
+
         if instance.host != CONF.host:
             self._undefine_domain(instance)
             self.unplug_vifs(instance, network_info)
             self.unfilter_instance(instance, network_info)
+            self.image_backend.backend().disconnect_disks(instance)
 
     def _get_volume_driver(self, connection_info):
         driver_type = connection_info.get('driver_volume_type')
@@ -1352,7 +1381,7 @@ class LibvirtDriver(driver.ComputeDriver):
         image_format = CONF.libvirt.snapshot_image_format or source_type
 
         # NOTE(bfilippov): save lvm and rbd as raw
-        if image_format == 'lvm' or image_format == 'rbd':
+        if image_format in ('lvm', 'rbd', 'sio'):
             image_format = 'raw'
 
         metadata = self._create_snapshot_metadata(base,
@@ -1375,7 +1404,7 @@ class LibvirtDriver(driver.ComputeDriver):
         if (self._host.has_min_version(MIN_LIBVIRT_LIVESNAPSHOT_VERSION,
                                        MIN_QEMU_LIVESNAPSHOT_VERSION,
                                        REQ_HYPERVISOR_LIVESNAPSHOT)
-             and source_type not in ('lvm', 'rbd')
+             and source_type not in ('lvm', 'rbd', 'sio')
              and not CONF.ephemeral_storage_encryption.enabled
              and not CONF.workarounds.disable_libvirt_livesnapshot):
             live_snapshot = True
@@ -2784,6 +2813,8 @@ class LibvirtDriver(driver.ComputeDriver):
                 size = None
 
             backend = image('disk')
+            if instance.task_state == task_states.RESIZE_FINISH:
+                backend.create_snap(libvirt_utils.RESIZE_SNAPSHOT_NAME)
             if backend.SUPPORTS_CLONE:
                 def clone_fallback_to_fetch(*args, **kwargs):
                     try:
@@ -4539,6 +4570,8 @@ class LibvirtDriver(driver.ComputeDriver):
                                CONF.libvirt.images_volume_group)
         elif CONF.libvirt.images_type == 'rbd':
             info = LibvirtDriver._get_rbd_driver().get_pool_info()
+        elif CONF.libvirt.images_type == 'sio':
+            info = LibvirtDriver._get_sio_driver().get_pool_info()
         else:
             info = libvirt_utils.get_fs_info(CONF.instances_path)
 
@@ -5113,7 +5146,6 @@ class LibvirtDriver(driver.ComputeDriver):
         """
         if (CONF.libvirt.images_type == dest_check_data.get('image_type') and
                 self.image_backend.backend().is_shared_block_storage()):
-            # NOTE(dgenin): currently true only for RBD image backend
             return True
 
         if (dest_check_data.get('is_shared_instance_path') and
@@ -5825,7 +5857,9 @@ class LibvirtDriver(driver.ComputeDriver):
                 raise exception.DestinationDiskExists(path=instance_dir)
             os.mkdir(instance_dir)
 
-            if not is_shared_block_storage:
+            if is_shared_block_storage:
+                self.image_backend.backend().connect_disks(instance)
+            else:
                 # Ensure images and backing files are present.
                 self._create_images_and_backing(
                     context, instance, instance_dir, disk_info,
@@ -6070,6 +6104,10 @@ class LibvirtDriver(driver.ComputeDriver):
             disk_dev = vol['mount_device'].rpartition("/")[2]
             volume_devices.add(disk_dev)
 
+        no_block_devices = (
+            block_device_info is not None and
+            self.image_backend.backend().is_shared_block_storage())
+
         disk_info = []
         doc = etree.fromstring(xml)
         disk_nodes = doc.findall('.//devices/disk')
@@ -6096,6 +6134,11 @@ class LibvirtDriver(driver.ComputeDriver):
                           'volume', {'path': path, 'target': target})
                 continue
 
+            if no_block_devices and disk_type == 'block':
+                LOG.debug('skipping disk %(path)s as it may belong to '
+                          'used shared block storage')
+                continue
+
             # get the real disk size or
             # raise a localized error if image is unavailable
             if disk_type == 'file':
@@ -6514,6 +6557,25 @@ class LibvirtDriver(driver.ComputeDriver):
                                                       image_ref,
                                                       instance)
 
+        backend = self.image_backend.image(instance, 'disk')
+        # Once we rollback, the snapshot is no longer needed, so remove it
+        # TODO(nic): Remove the try/except/finally in a future release
+        # To avoid any upgrade issues surrounding instances being in pending
+        # resize state when the software is updated, this portion of the
+        # method logs exceptions rather than failing on them.  Once it can be
+        # reasonably assumed that no such instances exist in the wild
+        # anymore, the try/except/finally should be removed,
+        # and ignore_errors should be set back to False (the default) so
+        # that problems throw errors, like they should.
+        try:
+            backend.rollback_to_snap(libvirt_utils.RESIZE_SNAPSHOT_NAME)
+        except exception.SnapshotNotFound:
+            LOG.warning(_LW("Failed to rollback snapshot (%s)"),
+                        libvirt_utils.RESIZE_SNAPSHOT_NAME)
+        finally:
+            backend.remove_snap(libvirt_utils.RESIZE_SNAPSHOT_NAME,
+                                ignore_errors=True)
+
         disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type,
                                             instance,
                                             image_meta,
diff --git a/nova/virt/libvirt/imagebackend.py b/nova/virt/libvirt/imagebackend.py
index f5e464e..8f17758 100644
--- a/nova/virt/libvirt/imagebackend.py
+++ b/nova/virt/libvirt/imagebackend.py
@@ -40,6 +40,7 @@ from nova.virt.libvirt import config as vconfig
 from nova.virt.libvirt import dmcrypt
 from nova.virt.libvirt import lvm
 from nova.virt.libvirt import rbd_utils
+from nova.virt.libvirt import sio_utils
 from nova.virt.libvirt import utils as libvirt_utils
 
 __imagebackend_opts = [
@@ -375,6 +376,49 @@ class Image(object):
         """Get an image's name of a base file."""
         return os.path.split(base)[-1]
 
+    def create_snap(self, name):
+        """Create a snapshot on the image.  A noop on backends that don't
+        support snapshots.
+
+        :param name: name of the snapshot
+        """
+        pass
+
+    def remove_snap(self, name, ignore_errors=False):
+        """Remove a snapshot on the image.  A noop on backends that don't
+        support snapshots.
+
+        :param name: name of the snapshot
+        :param ignore_errors: don't log errors if the snapshot does not exist
+        """
+        pass
+
+    def rollback_to_snap(self, name):
+        """Rollback the image to the named snapshot. A noop on backends that
+        don't support snapshots.
+
+        :param name: name of the snapshot
+        """
+        pass
+
+    @staticmethod
+    def connect_disks(instance):
+        """Connect existing instance disks to the compute host.
+
+        Makes existing instance disks available to use with libvirt.
+
+        :param instance: instance object
+        """
+        pass
+
+    @staticmethod
+    def disconnect_disks(instance):
+        """Disconnect instance disks from the compute host.
+
+        :param instance: instance object
+        """
+        pass
+
 
 class Raw(Image):
     def __init__(self, instance=None, disk_name=None, path=None):
@@ -835,6 +879,108 @@ class Ploop(Image):
             create_ploop_image(base, self.path, size)
 
 
+class Sio(Image):
+
+    def __init__(self, instance=None, disk_name=None, path=None):
+        # is_block_dev is False because True prevents ephemerals to be
+        # formatted and mounted due to a bug with creating of disk template
+        # in create_image call path
+        super(Sio, self).__init__("block", "raw", is_block_dev=False)
+
+        # TODO(emc): Currently we assume a static ScaleIO protection domain
+        # and storage pool. In the future we will need to have the API library
+        # determine what protection domain and storage pool to use based on
+        # the compute host node  information. For now if defined use values
+        # present in conf file
+        self.driver = sio_utils.SIODriver()
+
+        if path:
+            vol_id = path.split('-')[-1]
+            self.volume_name = self.driver.get_volume_name(vol_id)
+            self.path = path
+        else:
+            self.volume_name = sio_utils.get_sio_volume_name(instance,
+                                                             disk_name)
+            if self.driver.check_volume_exists(self.volume_name):
+                self.path = self.driver.get_volume_path(self.volume_name)
+            else:
+                self.path = None
+
+    @staticmethod
+    def is_shared_block_storage():
+        return True
+
+    @staticmethod
+    def connect_disks(instance):
+        sio_utils.SIODriver().map_volumes(instance)
+
+    @staticmethod
+    def disconnect_disks(instance):
+        sio_utils.SIODriver().cleanup_volumes(instance, unmap_only=True)
+
+    def check_image_exists(self):
+        # workaround to allow cache method to invoke create_image for resize
+        # operation
+        return False
+
+    def create_image(self, prepare_template, base, size, *args, **kwargs):
+        sio_utils.verify_volume_size(size)
+        if self.driver.check_volume_exists(self.volume_name):
+            vol_size = self.get_disk_size(self.volume_name)
+            if size < vol_size:
+                LOG.debug('Cannot resize volume %s to a smaller size.',
+                          self.volume_name)
+            elif size > vol_size:
+                self.driver.extend_volume(self.volume_name, size)
+
+            self.path = self.driver.map_volume(self.volume_name)
+        else:
+            if not os.path.exists(base):
+                prepare_template(target=base, max_size=size, *args, **kwargs)
+
+            base_size = disk.get_disk_size(base)
+            self.verify_base_size(base, size, base_size=base_size)
+
+            self.driver.create_volume(self.volume_name, size)
+            self.path = self.driver.map_volume(self.volume_name)
+            self.driver.import_image(base, self.path)
+
+    def get_disk_size(self, name):
+        return self.driver.get_volume_size(self.volume_name)
+
+    def libvirt_info(self, disk_bus, disk_dev, device_type, cache_mode,
+                     extra_specs, hypervisor_version):
+        if self.path is None:
+            raise exception.NovaException(
+                _('Disk volume %s is not connected') % self.volume_name)
+
+        info = super(Sio, self).libvirt_info(
+            disk_bus, disk_dev, device_type, cache_mode,
+            extra_specs, hypervisor_version)
+
+        # set is_block_dev to select proper backend driver,
+        # because ScaleIO volumes are block devices in fact
+        info.driver_name = libvirt_utils.pick_disk_driver_name(
+            hypervisor_version, is_block_dev=True)
+
+        return info
+
+    def snapshot_extract(self, target, out_format):
+        self.driver.export_image(self.path, target, out_format)
+
+    def create_snap(self, name):
+        snap_name = sio_utils.get_sio_snapshot_name(self.volume_name, name)
+        self.driver.snapshot_volume(self.volume_name, snap_name)
+
+    def remove_snap(self, name, ignore_errors=False):
+        snap_name = sio_utils.get_sio_snapshot_name(self.volume_name, name)
+        self.driver.remove_volume(snap_name)
+
+    def rollback_to_snap(self, name):
+        snap_name = sio_utils.get_sio_snapshot_name(self.volume_name, name)
+        self.driver.rollback_to_snapshot(self.volume_name, snap_name)
+
+
 class Backend(object):
     def __init__(self, use_cow):
         self.BACKEND = {
@@ -843,7 +989,8 @@ class Backend(object):
             'lvm': Lvm,
             'rbd': Rbd,
             'ploop': Ploop,
-            'default': Qcow2 if use_cow else Raw
+            'sio': Sio,
+            'default': Qcow2 if use_cow else Raw,
         }
 
     def backend(self, image_type=None):
diff --git a/nova/virt/libvirt/sio_utils.py b/nova/virt/libvirt/sio_utils.py
new file mode 100644
index 0000000..02209a4
--- /dev/null
+++ b/nova/virt/libvirt/sio_utils.py
@@ -0,0 +1,346 @@
+# Copyright (c) 2015 EMC Corporation
+# All Rights Reserved
+#
+# This software contains the intellectual property of EMC Corporation
+# or is licensed to EMC Corporation from third parties.  Use of this
+# software and the intellectual property contained therein is expressly
+# limited to the terms and conditions of the License Agreement under which
+# it is provided by or on behalf of EMC.
+#
+
+from oslo_concurrency import processutils
+from oslo_config import cfg
+from oslo_log import log as logging
+from oslo_utils import units
+
+from nova import exception
+from nova.i18n import _
+from nova import utils
+from nova.virt import images
+from nova.virt.libvirt import utils as libvirt_utils
+
+try:
+    import siolib
+    from siolib import scaleio
+    from siolib import utilities
+except ImportError:
+    siolib = None
+
+LOG = logging.getLogger(__name__)
+CONF = cfg.CONF
+
+if siolib:
+    CONF.register_group(siolib.SIOGROUP)
+    CONF.register_opts(siolib.SIOOPTS, siolib.SIOGROUP)
+
+VOLSIZE_MULTIPLE_GB = 8
+MAX_VOL_NAME_LENGTH = 31
+
+
+def verify_volume_size(requested_size):
+    """Verify that ScaleIO can have a volume with specified size.
+
+    ScaleIO creates volumes in multiples of 8.
+    :param requested_size: Size in bytes
+    :return: True if the size fit to ScaleIO, False otherwise
+    """
+    if (not requested_size or
+            requested_size % (units.Gi * VOLSIZE_MULTIPLE_GB)):
+        raise exception.NovaException(
+            _('Invalid disk size %s GB for the instance. The correct size '
+              'must be multiple of 8 GB. Choose another flavor') %
+            (requested_size / float(units.Gi)
+             if isinstance(requested_size, int) else
+             requested_size))
+
+
+def get_sio_volume_name(instance, disk_name):
+    """Generate ScaleIO volume name for instance disk.
+
+    ScaleIO restricts volume names to be unique, less than 32 symbols,
+    consist of alphanumeric symbols only.
+    Generated volume names start with a prefix, unique for the instance.
+    This allows one to find all instance volumes among all ScaleIO volumes.
+    :param instane: instance object
+    :param disk_name: disk name (i.e. disk, disk.local, etc)
+    :return: The generated name
+    """
+    sio_name = utilities.encode_base64(instance.uuid)
+    if disk_name.startswith('disk.'):
+        sio_name += disk_name[len('disk.'):]
+    elif disk_name != 'disk':
+        sio_name += disk_name
+    if len(sio_name) > MAX_VOL_NAME_LENGTH:
+        raise RuntimeError(_("Disk name '%s' is too long for ScaleIO") %
+                           disk_name)
+    return sio_name
+
+
+def get_sio_snapshot_name(volume_name, snapshot_name):
+    if snapshot_name == libvirt_utils.RESIZE_SNAPSHOT_NAME:
+        return volume_name + '/~'
+    sio_name = '%s/%s' % (volume_name, snapshot_name)
+    if len(sio_name) > MAX_VOL_NAME_LENGTH:
+        raise RuntimeError(_("Snapshot name '%s' is too long for ScaleIO") %
+                           snapshot_name)
+    return sio_name
+
+
+def probe_partitions(device_path, run_as_root=False):
+    """Method called to trigger OS and inform the OS of partition table changes
+
+    When ScaleIO maps a volume, there is a delay in the time the OS trigger
+    probes for partitions. This method will force that trigger so the OS
+    will see the device partitions
+    :param device_path: Full device path to probe
+    :return: Nothing
+    """
+    try:
+        utils.execute('partprobe', device_path, run_as_root=run_as_root)
+    except processutils.ProcessExecutionError as exc:
+        LOG.debug("Probing the device partitions has failed. (%s)", exc)
+
+
+class SIODriver(object):
+    """Backend image type driver for ScaleIO"""
+
+    pd_name = None
+    sp_name = None
+
+    def __init__(self, domain_name=None, pool_name=None):
+        """Initialize ScaleIODriver object.
+
+        :param domain_name: ScaleIO protection domain name
+        :param pool_name:  ScaleIO storage pool name
+        :return: Nothing
+        """
+        if siolib is None:
+            raise RuntimeError(_('ScaleIO python libraries not found'))
+
+        if domain_name and pool_name:
+            self.pd_name = domain_name.encode('utf8')
+            self.sp_name = pool_name.encode('utf8')
+
+        # IOCTL reference to ScaleIO API python library
+        self.ioctx = scaleio.ScaleIO(pd_name=self.pd_name,
+                                     sp_name=self.sp_name,
+                                     conf=CONF)
+
+    def get_pool_info(self):
+        """Return the total storage pool info."""
+
+        used_bytes, total_bytes, free_bytes = (
+            self.ioctx.storagepool_size(by_sds=True))
+        return {'total': total_bytes,
+                'free': free_bytes,
+                'used': used_bytes}
+
+    def create_volume(self, name, size):
+        """Create a ScaleIO volume.
+
+        :param name: Volume name to use
+        :param size: Size of volume to create
+        :return: Nothing
+        """
+        # NOTE(ft): siolib does not raise an exception if the volume
+        # already exists
+        self.ioctx.create_volume(name, size / units.Gi)
+
+    def remove_volume(self, name, ignore_mappings=False):
+        """Deletes (removes) a ScaleIO volume.
+
+        Removal of a volume erases all the data on the corresponding volume.
+
+        :param name: String ScaleIO volume name to remove
+        :param ignore_mappings: Remove even if the volume is mapped to SDCs
+        :return: Nothing
+        """
+        vol_id = self.ioctx.get_volumeid(name)
+        if vol_id:
+            self.ioctx.delete_volume(vol_id, unmap_on_delete=ignore_mappings)
+
+    def map_volume(self, name):
+        """Connect to ScaleIO volume.
+
+        Map ScaleIO volume to local block device
+
+        :param name: String ScaleIO volume name to attach
+        :return: Local attached volume path
+        """
+        vol_id = self.get_volume_id(name)
+        self.ioctx.attach_volume(vol_id)
+        path = self.ioctx.get_volumepath(vol_id)
+        # NOTE(ft): siolib does not raise an exception if it failed to attach
+        # the volume
+        if not path:
+            raise RuntimeError(_('Failed to attach disk volume %s') % name)
+
+        return path
+
+    def unmap_volume(self, name):
+        """Disconnect from ScaleIO volume.
+
+        Unmap ScaleIO volume from local block device
+
+        :param name: String ScaleIO volume name to detach
+        :return: Nothing
+        """
+        vol_id = self.ioctx.get_volumeid(name)
+        if vol_id:
+            self.ioctx.detach_volume(vol_id)
+
+    def check_volume_exists(self, name):
+        """Check if ScaleIO volume exists.
+
+        :param name: String ScaleIO volume name to check
+        :return: True if the volume exists, False otherwise
+        """
+        return bool(self.ioctx.get_volumeid(name))
+
+    def get_volume_id(self, name):
+        """Return the ScaleIO volume ID
+
+        :param name: String ScaleIO volume name to retrieve id from
+        :return: ScaleIO volume id
+        """
+        vol_id = self.ioctx.get_volumeid(name)
+        if not vol_id:
+            raise RuntimeError(_('Disk volume %s does not exist') % name)
+        return vol_id
+
+    def get_volume_name(self, vol_id):
+        """Return the ScaleIO volume name.
+
+        :param vol_id: String ScaleIO volume id to retrieve name from
+        :return: ScaleIO volume name
+        """
+        vol_name = None
+        try:
+            vol_name = self.ioctx.get_volumename(vol_id)
+        except AttributeError:
+            # Workaround siolib bug if the volume does not exist
+            pass
+
+        if not vol_name:
+            raise RuntimeError(_('Disk volume %s does not exist') % vol_id)
+
+        return vol_name
+
+    def get_volume_path(self, name):
+        """Return the volume device path location.
+
+        :param name: String ScaleIO volume name to get path information about
+        :return: Local attached volume path, None if the volume does not exist
+                 or is not connected
+        """
+        vol_id = self.get_volume_id(name)
+        return self.ioctx.get_volumepath(vol_id)
+
+    def get_volume_size(self, name):
+        """Return the size of the ScaleIO volume
+
+        :param name: String ScaleIO volume name to get path information about
+        :return: Size of ScaleIO volume
+        """
+        vol_id = self.get_volume_id(name)
+        vol_size = self.ioctx.get_volumesize(vol_id)
+        return vol_size * units.Ki
+
+    def import_image(self, source, dest):
+        """Import glance image onto actual ScaleIO block device.
+
+        :param source: Glance image source
+        :param dest: Target ScaleIO block device
+        :return: Nothing
+        """
+        info = images.qemu_img_info(source)
+        images.convert_image(source, dest, info.file_format, 'raw',
+                             run_as_root=True)
+        # trigger OS probe of partition devices
+        probe_partitions(device_path=dest, run_as_root=True)
+
+    def export_image(self, source, dest, out_format):
+        """Export ScaleIO volume.
+
+        :param source: Local attached ScaleIO volume path to export from
+        :param dest: Target path
+        :param out_format: Output format (raw, qcow2, etc)
+        :return: Nothing
+        """
+        images.convert_image(source, dest, 'raw', out_format, run_as_root=True)
+
+    def extend_volume(self, name, new_size):
+        """Extend the size of a volume.
+
+        This method is used primarily with openstack resize operation
+
+        :param name: String ScaleIO volume name to extend
+        :param new_size: Size of the volume to extend to
+        :return: Nothing
+        """
+        vol_id = self.get_volume_id(name)
+        self.ioctx.extend_volume(vol_id, new_size / units.Gi)
+        # NOTE(ft): siolib does not raise an exception if it cannot extend
+        # the volume
+        if self.get_volume_size(name) != new_size:
+            raise RuntimeError(_('Failed to extend disk volume %s') % name)
+
+    def snapshot_volume(self, name, snapshot_name):
+        """Snapshot a volume.
+
+        :param name: String ScaleIO volume name to make a snapshot
+        :param snapshot_name: String ScaleIO snapshot name to create
+        :return: Nothing
+        """
+        vol_id = self.get_volume_id(name)
+        snap_gid, _vol_list = self.ioctx.snapshot_volume(snapshot_name, vol_id)
+        # NOTE(ft): siolib does not rais an exception if it cannot create
+        # the snapshot
+        if not snap_gid:
+            raise RuntimeError(_('Failed to create snapshot of disk volume %s')
+                               % name)
+
+    def rollback_to_snapshot(self, name, snapshot_name):
+        """Rollback a snapshot.
+
+        :param name: String ScaleIO volume name to rollback to a snapshot
+        :param snapshot_name: String ScaleIO snapshot name to rollback to
+        :return: Nothing
+        """
+        snap_id = self.get_volume_id(snapshot_name)
+        self.remove_volume(name, ignore_mappings=True)
+        self.ioctx.rename_volume(snap_id, name)
+        if not self.check_volume_exists(name):
+            raise RuntimeError(_('Failed to rename snapshot %(snapshot)s '
+                                 'to disk volume %(disk)s') %
+                               {'disk': name,
+                                'snapshot_name': snapshot_name})
+        self.map_volume(name)
+
+    def map_volumes(self, instance):
+        """Map all instance volumes to its compute host.
+
+        :param intance: Instance object
+        :return: Nothing
+        """
+        volumes = self.ioctx.list_volume_names()
+        prefix = utilities.encode_base64(instance.uuid)
+        volumes = (vol for vol in volumes if vol.startswith(prefix))
+        for volume in volumes:
+            self.map_volume(volume)
+
+    def cleanup_volumes(self, instance, unmap_only=False):
+        """Cleanup all instance volumes.
+
+        :param instance: Instance object
+        :param unmap_only: Do not remove, only unmap from the instance host
+        :return: Nothing
+        """
+        volumes = self.ioctx.list_volume_names()
+        prefix = utilities.encode_base64(instance.uuid)
+        volumes = (vol for vol in volumes if vol.startswith(prefix))
+        for volume in volumes:
+            if unmap_only:
+                self.unmap_volume(volume)
+            else:
+                self.remove_volume(volume, ignore_mappings=True)
diff --git a/nova/virt/libvirt/utils.py b/nova/virt/libvirt/utils.py
index 6a0f7dd..eb83eb3 100644
--- a/nova/virt/libvirt/utils.py
+++ b/nova/virt/libvirt/utils.py
@@ -50,6 +50,8 @@ CONF.register_opts(libvirt_opts, 'libvirt')
 CONF.import_opt('instances_path', 'nova.compute.manager')
 LOG = logging.getLogger(__name__)
 
+RESIZE_SNAPSHOT_NAME = 'nova-resize'
+
 
 def execute(*args, **kwargs):
     return utils.execute(*args, **kwargs)
@@ -490,6 +492,8 @@ def find_disk(virt_dom):
 
 def get_disk_type_from_path(path):
     """Retrieve disk type (raw, qcow2, lvm) for given file."""
+    if path.startswith('/dev/disk/by-id/emc-vol'):
+        return 'sio'
     if path.startswith('/dev'):
         return 'lvm'
     elif path.startswith('rbd:'):
